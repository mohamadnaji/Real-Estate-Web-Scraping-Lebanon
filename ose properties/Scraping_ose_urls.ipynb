{"cells":[{"cell_type":"code","source":["pip install selenium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dJBtyQq1Byj","executionInfo":{"status":"ok","timestamp":1720210737648,"user_tz":-180,"elapsed":24657,"user":{"displayName":"Mohamad Naji","userId":"14781419396110170563"}},"outputId":"706d745a-773e-4fbc-ec72-64d716464d94"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.26.0-py3-none-any.whl (475 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.6.2)\n","Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n","Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.22.0 trio-0.26.0 trio-websocket-0.11.1 wsproto-1.2.0\n"]}]},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import os\n","import concurrent.futures\n","from bs4 import BeautifulSoup\n","from google.colab import files\n","from google.colab import drive\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import requests\n","import time\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.common.exceptions import TimeoutException\n","from requests.exceptions import ConnectionError, Timeout, TooManyRedirects, RequestException"],"metadata":{"id":"7sO1UhVKhiKt","executionInfo":{"status":"ok","timestamp":1720210738687,"user_tz":-180,"elapsed":1047,"user":{"displayName":"Mohamad Naji","userId":"14781419396110170563"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9eAJ66YMAdS","executionInfo":{"status":"ok","timestamp":1720210794355,"user_tz":-180,"elapsed":55675,"user":{"displayName":"Mohamad Naji","userId":"14781419396110170563"}},"outputId":"0d281787-4165-407e-9ab4-2136cadc6edf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Function to scrape URLs with a specific prefix\n","def scrape_urls_with_prefix(uri, param):\n","    try:\n","        # Create a WebDriver instance\n","        url = uri + param\n","\n","        # Proceed with Selenium if the status is OK\n","        options = webdriver.ChromeOptions()\n","        options.add_argument('--headless')\n","        options.add_argument('--no-sandbox')\n","        options.add_argument('--disable-dev-shm-usage')\n","        options.add_argument('--disable-extensions')\n","        options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n","        # Add any required options here\n","        browser = webdriver.Chrome(options=options)\n","\n","        # Navigate to the webpage\n","        browser.get(url)\n","\n","        # Wait for the page to fully load\n","        wait = WebDriverWait(browser, 10)\n","        wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n","\n","        time.sleep(2)\n","\n","        # Scroll down incrementally\n","        for i in range(10):  # Scroll down 10 times\n","            browser.execute_script(\"window.scrollBy(0, 800);\")\n","            time.sleep(0.5)  # Adjust sleep time if needed\n","\n","        # Once fully loaded, retrieve the page source\n","        page_source = browser.page_source\n","\n","        # Parse the HTML content\n","        soup = BeautifulSoup(page_source, 'html.parser')\n","\n","        # Find all 'a' tags\n","        # Select all elements with an ID that starts with 'prefix'\n","        elements = soup.select('[id^=prp_link_id_]')\n","\n","\n","        url_commercial = 'https://www.ose-properties.com/properties/'\n","        # Extract the href attribute of each a tag that starts with the specified prefix\n","        filtered_urls = [a.get('href') for a in elements if a.get('href') and a.get('href').startswith(url_commercial)]\n","        sett = set(filtered_urls)\n","        print(f\"Scraped {len(sett)} URLs from {url}\")\n","        return sett\n","\n","    except ConnectionError as e:\n","        print(\"Error in url \", url)\n","        print(f\"Connection error occurred: {e}\")\n","    except Timeout as e:\n","        print(\"Error in url \", url)\n","        print(f\"Timeout error occurred: {e}\")\n","    except TooManyRedirects as e:\n","        print(\"Error in url \", url)\n","        print(f\"Too many redirects: {e}\")\n","    except RequestException as e:\n","        print(\"Error in url \", url)\n","        print(f\"An error occurred: {e}\")\n","    except Exception as e:\n","\n","        print(\"Error in url \", url)\n","        print(f\"An error occurred: {e}\")\n","    except TimeoutException as e:\n","\n","        print(\"Error in url \", url)\n","        print(\"An error occurred: Timeout while loading the page or finding elements.\")\n","    finally:\n","        browser.close()\n","        browser.quit()\n","\n","def scrape_urls(initial_url):\n","    urls = set()\n","    idx = 1\n","    while idx<=13:\n","        # Scrape URLs with the specified prefix\n","        print(f'Scraping page {idx}')\n","        new_urls = scrape_urls_with_prefix(initial_url, f'?wplpage={idx}')\n","        if new_urls is None:\n","            break\n","        urls.update(new_urls)\n","        idx += 1\n","    return urls\n","\n","\n","def save_urls_to_csv(url, csv_file_path):\n","\n","    url = scrape_urls(url)\n","    print(f'Number of urls: {len(url)}')\n","\n","    # Convert set to list\n","    data_list = list(url)\n","\n","    # Create a DataFrame from the list\n","    df = pd.DataFrame(data_list, columns=['URL'])\n","\n","    # Save the DataFrame to an Excel file\n","    df.to_csv(csv_file_path, index=False)\n","\n","\n","url_sale = 'https://www.ose-properties.com/rent/'\n","csv_file_path_sale = '/content/drive/MyDrive/M2 final project/ose properties/urls_to_be_scraped_rent.csv'\n","\n","save_urls_to_csv(url_sale, csv_file_path_sale)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMgSkXMvwVRv","outputId":"47a4bf64-534d-4926-871c-6cd6c9990aa9","executionInfo":{"status":"ok","timestamp":1720211124772,"user_tz":-180,"elapsed":283581,"user":{"displayName":"Mohamad Naji","userId":"14781419396110170563"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraping page 1\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=1\n","Scraping page 2\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=2\n","Scraping page 3\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=3\n","Scraping page 4\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=4\n","Scraping page 5\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=5\n","Scraping page 6\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=6\n","Scraping page 7\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=7\n","Scraping page 8\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=8\n","Scraping page 9\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=9\n","Scraping page 10\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=10\n","Scraping page 11\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=11\n","Scraping page 12\n","Scraped 12 URLs from https://www.ose-properties.com/rent/?wplpage=12\n","Scraping page 13\n","Scraped 9 URLs from https://www.ose-properties.com/rent/?wplpage=13\n","Number of urls: 153\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiCFec1fbf5kRq4Q99KZXh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}